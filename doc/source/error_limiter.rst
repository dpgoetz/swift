=============
Error Limiter
=============

Swift is a distributed system built to prevent single node failures from
affecting the total cluster's performance. For example, on an object GET, if
the object server the proxy uses isn't responding the proxy will just go on to
the next one from the ring and the client gets the object. If, however, the
object server is just slow and is continually causing read timeouts then, for
objects going to that server, the client will still get that object but will
have to wait for that timeout to trigger (when the proxy will try the next node
in the ring). By default, that timeout is 10 seconds- quite long. This error
limiting is supposed to help prevent sending requests to these bad nodes in the
first place.

----------------
How it is set up
----------------

Each proxy server will share a SQLite database to keep track of the error
limiting data. By default, this is kept in /var/run/swift/error-limiter (which
will need to be made by an admin with permissions set to be writable by the
proxy server processes), in a tmpfs, which means the database is only stored in
memory, making it much faster. The database is rotated out every 12 hours (by
default) and old databases are removed. All the proxy server workers on the
server will share this database but no sharing of error-limiting data is shared
outside of this.  This could be seen as a limitation to the system but it
simplifies the implementation and also prevents certain types of problems (for
example, a network failure between one proxy and one object node or zone) from
affecting the rest of the proxies without reason.

------------
How it works
------------

A record of every transaction to and timeout caused by a node
(object/container/account) is kept in the database using a key built out of the
node dict and a time window. By default, the key is made using
'%(ip)s_%(port)s' and the time window is unix-time / 60. At this point, there
is no separation between types of requests. When the proxy is iterating through
the nodes given to it from the ring it will ask the error limiter if this node
has been limited. If the node is being limited it will be skipped, however a
max of 1 (configurable) nodes will be skipped because of this error limiting. A
moving weighted average of the ratio of errors to timeouts is used to determine
if the node is limited. For example with the following database rows:

node_id        time_window        # transactions   # errors
-----------------------------------------------------------
1.1.1.1:6000   [time() / 60]       10               5
1.1.1.1:6000   [time() / 60 - 1]   8                0
1.1.1.1:6000   [time() / 60 - 2]   4                3
1.1.1.1:6000   [time() / 60 - 3]   7                2
1.1.1.1:6000   [time() / 60 - 4]   11               4

limited_average = float((5 * 5) + (0 * 3) + (3 * 2) + (2 * 1) + (4 * 1)) /
     ((10 * 5) + (8 * 3) + (4 * 2) + (7 * 1) + (11 * 1))

which resolves to 0.37. So:

if random() < limited_average:
    return True  # the node is limited.

The series  of weights: 5, 3, 2, 1, 1 is generated by
round(# lookback_windows / # windows passed).
The number of lookback_windows and size per window is configurable and defaults
to 5 and 60 respectively.

----------------
How to deploy it
----------------

On every proxy server create the directory:

/var/run/swift/error-limiter

Give that directory write permissions to the user you run the proxy
servers as.

in :ref:`proxy-server-config`) add the line:

error_limit_config = default

to the [app:proxy-server] section.

To change from the default, make a new config file as seen in:

error_limiter.conf-sample

and set:

error_limit_config = /path/to/that/conf

in the proxy-server.conf
